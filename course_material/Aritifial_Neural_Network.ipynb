{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import expit\n",
    "from decimal import Decimal\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks\n",
    "\n",
    "Here we will take a closer look at Neural Netorks, also known as Artificial Neural Networks (ANN) to destinuish them from their biological counterparts and Convolutional Neural Networks (CNN); which will be covered in the next session.\n",
    "\n",
    "ANNs simulate the brain architecture in that neurons take gets input from synapses and give output to other neurons, thereby forming a directed graph.  \n",
    "\n",
    "![General neural net graph](./images/general-ann.png)\n",
    "\n",
    "The topology of this graph can be quite diverse, however we will start with a simple example. We will tag some nodes as special input nodes and some as special output nodes. This is were we will attach the input-output training data to later. The rest of the nodes are simply called \"hidden nodes\"\n",
    "\n",
    "![Simple ANN](./images/Artificial_neural_network.svg)\n",
    "\n",
    "A single neuron takes multiple inputs $x_i$ and give a single output (possible to more than one reciever). The inputs are weighted by some $\\theta_i$ (including the bias $\\theta_0$) to compute an *activation*\n",
    "\n",
    "$z = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation(x, theta):\n",
    "    answer = theta[0]\n",
    "    for i in range(len(x)):\n",
    "        answer += x[i]*theta[i+1]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However the activation is typically passed through an activation function. This introduces non-linearity into the formulation which greatly helps in generalizing to complex problems. Different activation functions are available, but the two must videly used are the\n",
    "\n",
    "## sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))\n",
    "\n",
    "z = np.linspace(-8,8)\n",
    "plt.plot(z, sigmoid(z))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rectified linear unit (relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(z,0)\n",
    "\n",
    "z = np.linspace(-8,8)\n",
    "plt.plot(z, relu(z))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a single neuron with input weights $\\theta_i$ can then be programmed as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron(x,theta):\n",
    "    return sigmoid(activation(x,theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if one choses the sigmoid activation function. The entire network described above can be written as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define some input vector\n",
    "x = [1,3,13]\n",
    "\n",
    "# compute output for hidden units\n",
    "a1 = neuron(x, [3,1,1,1]) # output from hidden neuron 1 using weights [3,1,1,1] (first weight is the bias)\n",
    "a2 = neuron(x, [1,1,2,1]) # output from hidden neuron 2 using weights [1,1,2,1]\n",
    "a3 = neuron(x, [0,3,2,1]) # output from hidden neuron 2 using weights [0,3,2,1]\n",
    "a4 = neuron(x, [2,0,0,1]) # output from hidden neuron 2 using weights [2,0,0,1]\n",
    "a  = [a1,a2,a3,a4]      # wrap all hidden values into a vector\n",
    "\n",
    "# compute output nodes\n",
    "y1 = neuron(a, [1,0,0,1,3]) # output neuron 1 using weights [1,0,0,1,3] (first weight is the bias)\n",
    "y2 = neuron(a, [1,3,9,1,0]) # output neuron 2 using weights [1,3,9,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that every neuron $i$ has a different weight $\\theta_j$ and we often denote $\\Theta_{ij}$\n",
    "\n",
    "$$z = \\Theta^{(1)} \\left[\\begin{array}{c} 1 \\\\ x \\end{array}\\right]$$\n",
    "\n",
    "where, in this case we have\n",
    "\n",
    "$$ \\Theta^{(1)} = \\left[ \\begin{array}{cccc} 3 & 1 & 1 & 1 \\\\ 1 & 1 & 2 & 1 \\\\ 0 & 3 & 2 & 1 \\\\ 2 & 0 & 0 & 1\\end{array}\\right]$$\n",
    "\n",
    "Then we compute the activation function (for instance the sigmoid function $\\sigma$) and pass this to the next level of the network\n",
    "\n",
    "$$ a = \\sigma(z)$$\n",
    "\n",
    "Likewise, the output nodes will also have different weights and we write\n",
    "\n",
    "$$y = \\sigma\\left(\\Theta^{(2)} \\left[ \\begin{array}{c}1\\\\a\\end{array}\\right]\\right)$$\n",
    "\n",
    "$\\Theta^{(2)} =\\left[\\begin{array}{ccccc} 1 & 0 & 0 & 1 & 3 \\\\ 1 & 3 & 9 & 1 & 0 \\end{array}\\right]$ in this particular case. This vectorization allow us to create fast implementations of neural networks. $x$ and $y$ are as usual treated as the input and output respectively, while intermediate results are denoted $z$. \n",
    "\n",
    "Due to the optimzation possibilities, these *feed forward* networks have become very popular. We can extend this be adding more layers to it. By adding another layer we can start with a vector $x$, then compute a vector $p_1$ using a matrix of weights $\\Theta^{(1)}$. Subsequently we compute a vector $p_2$ using a matrix of weights $\\Theta^{(2)}$ followed by an output using $\\Theta^{(3)}$, giving the following network\n",
    "\n",
    "![Neural network with 2 hidden layers](./images/Artificial_neural_network_2layers.svg)\n",
    "\n",
    "We can control the architecture of the network and the activation functions used, but will not manually specify the weights $\\Theta$. This is trained using optimization algorithms using [backpropagation](https://en.wikipedia.org/wiki/Backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House price regression using neural networks\n",
    "\n",
    "For a single hidden layer neural network, then this collapses to logistic regression. We will here implement the network outlined above with a single output neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and normalize features\n",
    "def featureNormalize(X):\n",
    "    X_norm = X\n",
    "    mu    = np.zeros((1, X.shape[1]))\n",
    "    sigma = np.zeros((1, X.shape[1]))\n",
    "    for i in range(X.shape[1]):\n",
    "        mu[:,i] = np.mean(X[:,i])\n",
    "        sigma[:,i] = np.std(X[:,i])\n",
    "        X_norm[:,i] = (X[:,i] - float(mu[:,i]))/float(sigma[:,i])\n",
    "    return X_norm, mu, sigma\n",
    "\n",
    "data = np.loadtxt('./data/housing_data.csv', delimiter=\",\")\n",
    "X = data[:,:2]\n",
    "y = data[:,2]\n",
    "m = len(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will in the following use the square sum loss function\n",
    "$$\n",
    "J(\\Theta) = \\frac{1}{2m}\\sum(y-y_p)^2\n",
    "$$\n",
    "with the following gradient\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\Theta_ij} = \\frac{1}{m}\\sum(y-y_p)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(W,X,y):\n",
    "    (n,m) = X.shape # n features, m training examples\n",
    "    \n",
    "    Theta1 = np.reshape(W[  : 9], (3,3))\n",
    "    Theta2 = np.reshape(W[ 9:25], (4,4))\n",
    "    Theta3 = np.reshape(W[25:  ], (5,1))\n",
    "    z1 = Theta1 * np.vstack(np.ones((1,m)),  X)\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = Theta2 * np.vstack(np.ones((1,m)), a1)\n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = Theta3 * np.vstack(np.ones((1,m)), a2)\n",
    "    yp = sigmoid(z3) # predicted values for one feed-forward iteration\n",
    "    \n",
    "    loss = np.sum((yp-y)**2) / 2 / m\n",
    "    \n",
    "    # compute the jacobian by partial differentiation\n",
    "    return (loss, jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Neural Network...')\n",
    "maxiter = 1000\n",
    "lambda_reg = 0.1\n",
    "results = minimize(cost, x0=nn_params, args=(X,y), options={'disp': True, 'maxiter':maxiter}, method=\"L-BFGS-B\", jac=True)\n",
    "\n",
    "all_weights = results[\"x\"]\n",
    "\n",
    "Theta1 = np.reshape(all_weights[  : 9], (3,3), order='F')\n",
    "Theta2 = np.reshape(all_weights[ 9:25], (4,4), order='F')\n",
    "Theta3 = np.reshape(all_weights[25:  ], (5,1), order='F')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displayData(X, example_width=None):\n",
    "    m,n = X.shape\n",
    "    plt.figure(figsize=(16,16))\n",
    "    if X.ndim == 1:\n",
    "        X = np.reshape(X, (-1,m))\n",
    "    if not example_width or not 'example_width' in locals():\n",
    "        example_width = int(round(math.sqrt(X.shape[1])))\n",
    "    plt.set_cmap(\"gray\")\n",
    "    example_height = n / example_width\n",
    "    display_rows = int(math.floor(math.sqrt(m)))\n",
    "    display_cols = int(math.ceil(m / display_rows))\n",
    "    pad = 1\n",
    "    display_array = -np.ones((pad + display_rows * int(example_height + pad),  pad + display_cols * int(example_width + pad)))\n",
    "    curr_ex = 1\n",
    "    for j in range(1,display_rows+1):\n",
    "        for i in range (1,display_cols+1):\n",
    "            if curr_ex > m:\n",
    "                break\n",
    "            max_val = max(abs(X[curr_ex-1, :]))\n",
    "            rows = pad + (j - 1) * (int(example_height) + pad) + np.array(range(int(example_height)))\n",
    "            cols = pad + (i - 1) * (int(example_width)  + pad) + np.array(range(int(example_width)))\n",
    "            display_array[rows[0]:rows[-1]+1 , cols[0]:cols[-1]+1] = np.reshape(X[curr_ex-1, :], (int(example_height), int(example_width)), order=\"F\") / max_val\n",
    "            curr_ex += 1\n",
    "            if curr_ex > m:\n",
    "                break\n",
    "    h = plt.imshow(display_array.T, vmin=-1, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.show(block=False)\n",
    "    return h, display_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(Theta1, Theta2, X):\n",
    "    if X.ndim == 1:\n",
    "        X = np.reshape(X, (-1,X.shape[0]))\n",
    "    m = X.shape[0]\n",
    "    p = np.zeros((m,1))\n",
    "    X = np.column_stack((np.ones((m,1)), X))\n",
    "    a2 = sigmoid( np.dot(X,Theta1.T) )\n",
    "    a2 = np.column_stack((np.ones((a2.shape[0],1)), a2))\n",
    "    a3 = sigmoid( np.dot(a2,Theta2.T) )\n",
    "    p = np.argmax(a3, axis=1)\n",
    "    return p + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture of Deep Neural Network, Cost Function and Regularization\n",
    "<img src='./images/dnncost.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nnCostFunction(nn_params, input_layer_size, hidden_layer_size, \\\n",
    "\tnum_labels, X, y, lambda_reg):\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], \\\n",
    "                     (hidden_layer_size, input_layer_size + 1), order='F')\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):], \\\n",
    "                     (num_labels, hidden_layer_size + 1), order='F')\n",
    "    m = len(X)\n",
    "    J = 0;\n",
    "    Theta1_grad = np.zeros( Theta1.shape )\n",
    "    Theta2_grad = np.zeros( Theta2.shape )\n",
    "    X = np.column_stack((np.ones((m,1)), X)) # = a1\n",
    "    a2 = sigmoid( np.dot(X,Theta1.T) )\n",
    "    a2 = np.column_stack((np.ones((a2.shape[0],1)), a2))\n",
    "    a3 = sigmoid( np.dot(a2,Theta2.T) )\n",
    "\n",
    "    labels = y\n",
    "    #One hot encoding\n",
    "    y = np.zeros((m,num_labels))\n",
    "    for i in range(m):\n",
    "    \ty[i, labels[i]-1] = 1\n",
    "\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "    \tcost += np.sum( y[i] * np.log( a3[i] ) + (1 - y[i]) * np.log( 1 - a3[i] ) )\n",
    "    J = -(1.0/m)*cost\n",
    "    sumOfTheta1 = np.sum(np.sum(Theta1[:,1:]**2))\n",
    "    sumOfTheta2 = np.sum(np.sum(Theta2[:,1:]**2))\n",
    "    J = J + ( (lambda_reg/(2.0*m))*(sumOfTheta1+sumOfTheta2) )\n",
    "    bigDelta1 = 0\n",
    "    bigDelta2 = 0\n",
    "    for t in range(m):\n",
    "        x = X[t]\n",
    "        a2 = sigmoid( np.dot(x,Theta1.T))\n",
    "        a2 = np.concatenate((np.array([1]), a2))\n",
    "        a3 = sigmoid( np.dot(a2,Theta2.T) )\n",
    "        delta3 = np.zeros((num_labels))\n",
    "        for k in range(num_labels):\n",
    "            y_k = y[t, k]\n",
    "            delta3[k] = a3[k] - y_k\n",
    "        delta2 = (np.dot(Theta2[:,1:].T, delta3).T) * sigmoidGradient( np.dot(x, Theta1.T) )\n",
    "        bigDelta1 += np.outer(delta2, x)\n",
    "        bigDelta2 += np.outer(delta3, a2)\n",
    "    Theta1_grad = bigDelta1 / m\n",
    "    Theta2_grad = bigDelta2 / m\n",
    "    Theta1_grad_unregularized = np.copy(Theta1_grad)\n",
    "    Theta2_grad_unregularized = np.copy(Theta2_grad)\n",
    "    Theta1_grad += (float(lambda_reg)/m)*Theta1\n",
    "    Theta2_grad += (float(lambda_reg)/m)*Theta2\n",
    "    Theta1_grad[:,0] = Theta1_grad_unregularized[:,0]\n",
    "    Theta2_grad[:,0] = Theta2_grad_unregularized[:,0]\n",
    "    grad = np.concatenate((Theta1_grad.reshape(Theta1_grad.size, order='F'), Theta2_grad.reshape(Theta2_grad.size, order='F')))\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randInitializeWeights(L_in, L_out):\n",
    "    W = np.zeros((L_out, 1 + L_in))\n",
    "    epsilon_init = 0.12\n",
    "    W = np.random.rand(L_out, 1 + L_in)*(2*epsilon_init) - epsilon_init\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "_,input_layer_size  = X_train.shape  \n",
    "hidden_layer_size = 25   # 25 hidden units\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resulting 2 Layer Neural Network\n",
    "<img src='./images/ann.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_train\n",
    "y=y_train\n",
    "m,n=X.shape\n",
    "y=y.flatten()\n",
    "rand_indices = np.random.permutation(m)\n",
    "random_images = X[rand_indices[:100],:]\n",
    "displayData(random_images);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta1=randInitializeWeights(input_layer_size,hidden_layer_size)\n",
    "Theta2=randInitializeWeights(hidden_layer_size, num_labels)\n",
    "nn_params = np.concatenate((Theta1.reshape(Theta1.size, order='F'), Theta2.reshape(Theta2.size, order='F')))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Neural Network...')\n",
    "maxiter = 1000\n",
    "lambda_reg = 0.1\n",
    "myargs = (input_layer_size, hidden_layer_size, num_labels, X, y, lambda_reg)\n",
    "results = minimize(nnCostFunction, x0=nn_params, args=myargs, options={'disp': True, 'maxiter':maxiter}, method=\"L-BFGS-B\", jac=True)\n",
    "\n",
    "nn_params = results[\"x\"]\n",
    "\n",
    "Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], \\\n",
    "                 (hidden_layer_size, input_layer_size + 1), order='F')\n",
    "\n",
    "Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):], \\\n",
    "                 (num_labels, hidden_layer_size + 1), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nVisualizing Neural Network layer 1 \\n')\n",
    "displayData(Theta1[:, 1:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nVisualizing Neural Network layer 1 \\n')\n",
    "displayData(Theta2[:, 1:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(Theta1, Theta2, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment code below to see the predictions that don't match\n",
    "# fmt = '{}   {}'\n",
    "# print(fmt.format('y', 'pred'))\n",
    "# for y_elem, pred_elem in zip(y, pred):\n",
    "#     if y_elem != pred_elem:\n",
    "#         print(fmt.format(y_elem%10, pred_elem%10))\n",
    "\n",
    "print('Training Set Accuracy: {:f}'.format( ( np.mean(pred == y)*100 ) ) )\n",
    "\n",
    "#for i in range(m):\n",
    "#    print('Displaying Example Image')\n",
    "#    displayData(X[rp[i], :].reshape(1,-1))\n",
    "#    pred = predict(Theta1, Theta2, X[rp[i], :])\n",
    "#    print('Neural Network Prediction: {:d} (digit {:d})'.format(pred[0], (pred%10)[0]))\n",
    "#    input('Program paused. Press enter to continue.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve using Keras with Tensorflow backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a neural network to be for recoqnizing hand-written digits using the Keras library. First we will download and inspect the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This is a set of 60,000 images (28x28 pixels grayscale) of hand-written digits. We can display the first few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQhB8IivADQf0/sEWOix6VKakAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fa53f8ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/EBQhB8I6v8AG8x2aarNGp8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fa2bac0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8gNJUX4gKcoPJEX5gaQoP5DUnwER0gZdW5joZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fa545fd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()\n",
    "plt.imshow(X_train[1])\n",
    "plt.show()\n",
    "plt.imshow(X_train[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4]\n"
     ]
    }
   ],
   "source": [
    "# by inspecting the training labels, we see what these images are ment to show\n",
    "print(y_train[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEIAAAD8CAYAAADDlHLtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWqcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fa531a160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# we can plot the first 10 digits in a single plot by reshaping the image data\n",
    "plt.imshow(X_train[:10,:,:].reshape((28*10,28)))\n",
    "plt.show()\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now convert the input data to the right representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]]\n",
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# all inputs are defined as vectors, i.e. we collapse a 28x28 image to a 784 feature vector\n",
    "X  = X_train.reshape(60000,784)\n",
    "Xt = X_test.reshape(10000,784)\n",
    "\n",
    "# all outputs are defined as categorical values. We do a one-hot encoding of these\n",
    "categorical_transform = LabelBinarizer().fit(np.arange(10)) # labels are in the range [0,10]\n",
    "y  = categorical_transform.transform(y_train)\n",
    "yt = categorical_transform.transform(y_test)\n",
    "\n",
    "print(y[:10,:])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a Neural Network model in Keras using the Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# create a model of sequential layers \n",
    "model = Sequential()\n",
    "\n",
    "# add the first layer, this *requires* you to specify the input dimension (our 28*28=784 px images)\n",
    "model.add(Dense(input_dim=784, units = 100, activation='sigmoid'))\n",
    "\n",
    "# add the second layer. All layers require you to specify the number of neurons (units)\n",
    "model.add(Dense(               units =  50, activation='sigmoid'))\n",
    "\n",
    "# the third and final output layer. We here use the 'softmax' activation function since we want to classify\n",
    "# the numbers [0-9] with a percentage prediction\n",
    "model.add(Dense(               units =  10, activation='softmax'))\n",
    "\n",
    "# finish the model and compile it so it is ready for training\n",
    "model.compile(optimizer= 'adam',                     \n",
    "              loss     = 'categorical_crossentropy',\n",
    "              metrics  = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.7632 - acc: 0.8309 - val_loss: 0.3814 - val_acc: 0.9008\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.3507 - acc: 0.9026 - val_loss: 0.3212 - val_acc: 0.9074\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3204 - acc: 0.9059 - val_loss: 0.2864 - val_acc: 0.9151\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.2943 - acc: 0.9142 - val_loss: 0.2869 - val_acc: 0.9123\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2775 - acc: 0.9174 - val_loss: 0.2735 - val_acc: 0.9166\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2700 - acc: 0.9185 - val_loss: 0.2599 - val_acc: 0.9229\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2632 - acc: 0.9203 - val_loss: 0.2566 - val_acc: 0.9216\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2527 - acc: 0.9225 - val_loss: 0.2626 - val_acc: 0.9169\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2409 - acc: 0.9276 - val_loss: 0.2385 - val_acc: 0.9249\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2355 - acc: 0.9281 - val_loss: 0.2461 - val_acc: 0.9241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f99b45c50>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "         epochs=10,\n",
    "         batch_size=100,\n",
    "         validation_data=(Xt,yt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test our model on one of the test images. Remember that the test images are *not* used for updating the weights, so this is considered an unseen example image by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fa5475e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is actually a 1\n",
      "\n",
      "[[  6.81431970e-07   9.88680124e-01   2.59935798e-04   9.39901825e-03\n",
      "    3.33482285e-06   5.68995427e-04   2.63311904e-05   2.73413723e-04\n",
      "    6.65243657e-04   1.22930855e-04]]\n",
      "\n",
      "98.86801242828369 % chance of this being a 1\n"
     ]
    }
   ],
   "source": [
    "i = 14 # choose one test image index\n",
    "\n",
    "# show one of the test images\n",
    "plt.imshow(X_test[i,:,:])\n",
    "plt.show()\n",
    "print('This is actually a', y_test[i]) # this is what it is *supposed* to be\n",
    "print()\n",
    "\n",
    "# do a prediction using our model\n",
    "prediction = model.predict(X_test[i,:,:].reshape(1,28*28)) # remember to roll the image data into a vector\n",
    "\n",
    "# the prediction is a vector of 10 (output nodes) with % probability of that being the shown digit (softmax function)\n",
    "print(prediction)\n",
    "print()\n",
    "print('{} % chance of this being a {}'.format(prediction[0,y_test[i]]*100, y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually the weights are quite opaque, meaning that they are hard to interpret. In many applications this is not a problem; as the saying goes \"all models are wrong, some are usefull\". However if one wants a better understanding of what the model does, one can look at the equations. The predictions appear as a sequence of matrix-vector multiplications followed by application of the activation function. Ignoring the bias for now, they take the form:\n",
    "\n",
    "$$ z_1 = \\sigma\\left( \\Theta^{(1)} x  \\right) \\\\\n",
    "   z_2 = \\sigma\\left( \\Theta^{(2)} z_1\\right) \\\\\n",
    "   y   = \\sigma\\left( \\Theta^{(3)} z_2\\right) $$\n",
    "\n",
    "for our 3-layer neural network. Seing as the activation function, all take low values and map thems them to other low values and likewise for high values (monotonly growing function), it is not unreasonable to assume that a good approximation of neural importance comes from omitting the activation function to get\n",
    "\n",
    "$$ y \\approx \\Theta^{(3)} \\Theta^{(2)} \\Theta^{(1)} x $$\n",
    "\n",
    "If we call $\\Theta = \\Theta^{(3)} \\Theta^{(2)} \\Theta^{(1)}$, then this matrix will map from 784 image pixels to 10 digit predictions. We may get this matrix by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100, 50)\n",
      "(50, 10)\n",
      "(10, 784)\n"
     ]
    }
   ],
   "source": [
    "theta1 = model.layers[0].get_weights()[0] # returns a tuple of weights and the bias, we only care about weights now\n",
    "theta2 = model.layers[1].get_weights()[0]\n",
    "theta3 = model.layers[2].get_weights()[0]\n",
    "\n",
    "print(theta1.shape)\n",
    "print(theta2.shape)\n",
    "print(theta3.shape)\n",
    "# keras stores the weights as the transpose of the above, so we correct these\n",
    "theta1 = theta1.T\n",
    "theta2 = theta2.T\n",
    "theta3 = theta3.T\n",
    "theta = theta3.dot(theta2).dot(theta1)\n",
    "print(theta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seing as the inputs are considered image pixels, we may now draw reinpret the effect of $\\Theta$ as image pixels. We reshape from 784 to (28,28) and draw the 10 images resulting from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEIAAAD8CAYAAADDlHLtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKKKVDxTRygeKaOUDRbTygSJa+f8BaduTDKFtrzcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fa01548d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_intepretation = theta.reshape(28,28,10)\n",
    "plt.imshow(image_intepretation.reshape(28*10,28)) # reshape to 10 images down\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dark areas signify negative fedback while bright positive. Thus for the upper image, one can see a trace of a bright zero meaning that if pixel values in this region appears, this will count positively for this being the number '0'. The same image has a dark area in its center meaning that pixels in this region will count negative for this being a '0'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A stand-alone training model\n",
    "The above model can be compactly written as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# create preprocessor\n",
    "categorical_transform = LabelBinarizer().fit(np.arange(10))\n",
    "\n",
    "# load and transform data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X  = X_train.reshape(60000,784)\n",
    "Xt = X_test.reshape(10000,784)\n",
    "y  = categorical_transform.transform(y_train)\n",
    "yt = categorical_transform.transform(y_test)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=784, units = 100, activation='sigmoid'))\n",
    "model.add(Dense(               units =  50, activation='sigmoid'))\n",
    "model.add(Dense(               units =  10, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer= 'adam',                     \n",
    "              loss     = 'categorical_crossentropy',\n",
    "              metrics  = ['accuracy'])\n",
    "\n",
    "# train model\n",
    "model.fit(X, y,\n",
    "         epochs=10,\n",
    "         batch_size=100,\n",
    "         validation_data=(Xt,yt))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
