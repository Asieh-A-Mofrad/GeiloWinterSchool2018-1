{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import expit\n",
    "from decimal import Decimal\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks\n",
    "\n",
    "Here we will take a closer look at Neural Netorks, also known as Artificial Neural Networks (ANN) to destinuish them from their biological counterparts and Convolutional Neural Networks (CNN); which will be covered in the next session.\n",
    "\n",
    "ANNs simulate the brain architecture in that neurons take gets input from synapses and give output to other neurons, thereby forming a directed graph.  \n",
    "\n",
    "![General neural net graph](./images/general-ann.png)\n",
    "\n",
    "The topology of this graph can be quite diverse, however we will start with a simple example. We will tag some nodes as special input nodes and some as special output nodes. This is were we will attach the input-output training data to later. The rest of the nodes are simply called \"hidden nodes\"\n",
    "\n",
    "![Simple ANN](./images/Artificial_neural_network.svg)\n",
    "\n",
    "A single neuron takes multiple inputs $x_i$ and give a single output (possible to more than one reciever). The inputs are weighted by some $\\theta_i$ to compute an *activation*\n",
    "\n",
    "$z = \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation(x, theta):\n",
    "    answer = 0\n",
    "    for i in range(len(x)):\n",
    "        answer += x[i]*theta[i]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However the activation is typically passed through an activation function. This introduces non-linearity into the formulation which greatly helps in generalizing to complex problems. Different activation functions are available, but the two must videly used are the\n",
    "\n",
    "## sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x224a3526a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))\n",
    "\n",
    "z = np.linspace(-8,8)\n",
    "plt.plot(z, sigmoid(z))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rectified linear unit (relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x224a5c508d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(z,0)\n",
    "\n",
    "z = np.linspace(-8,8)\n",
    "plt.plot(z, relu(z))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a single neuron with input weights $\\theta_i$ can then be programmed as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron(x,theta):\n",
    "    return sigmoid(activation(x,theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if one choses the sigmoid activation function. Theentire network described above can be written as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define some input vector\n",
    "x = [1,3,13]\n",
    "\n",
    "# compute output for hidden units\n",
    "a1 = neuron(x, [1,1,1]) # output from hidden neuron 1 using weights [1,1,1]\n",
    "a2 = neuron(x, [1,2,1]) # output from hidden neuron 2 using weights [1,2,1]\n",
    "a3 = neuron(x, [3,2,1]) # output from hidden neuron 2 using weights [3,2,1]\n",
    "a4 = neuron(x, [0,0,1]) # output from hidden neuron 2 using weights [0,0,1]\n",
    "a  = [a1,a2,a3,a4]      # wrap all hidden values into a vector\n",
    "\n",
    "# compute output nodes\n",
    "y1 = neuron(a, [0,0,1,3]) # output neuron 1 using weights [0,0,1,3]\n",
    "y2 = neuron(a, [3,9,1,0]) # output neuron 2 using weights [3,9,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that every neuron $i$ has a different weight $\\theta_j$ and we often denote $\\Theta_{ij}$\n",
    "\n",
    "$a = \\sigma(\\Theta x)$\n",
    "\n",
    "Likewise, the output nodes will also have different weights and we write\n",
    "\n",
    "$y = \\sigma(\\Theta^{(2)} a)$\n",
    "\n",
    "where $\\sigma(\\cdot)$ is the activation function (here: sigmoid function). $\\Theta^{(2)} =\\left[\\begin{array}{cccc} 0 & 0 & 1 & 3 \\\\ 3 & 9 & 1 & 0 \\end{array}\\right]$ in this particular case. This vectorization allow us to create fast implementations of neural networks. $x$ and $y$ are as usual treated as the input and output respectively, while intermediate results are denoted $p$. \n",
    "\n",
    "Due to the optimzation possibilities, these *feed forward* networks have become very popular. We can extend this be adding more layers to it. By adding another layer we can start with a vector $x$, then compute a vector $p_1$ using a matrix of weights $\\Theta^{(1)}$. Subsequently we compute a vector $p_2$ using a matrix of weights $\\Theta^{(2)}$ followed by an output using $\\Theta^{(3)}$, giving the following network\n",
    "\n",
    "![Neural network with 2 hidden layers](./images/Artificial_neural_network_2layers.svg)\n",
    "\n",
    "We can control the architecture of the network and the activation functions used, but will not manually specify the weights $\\Theta$. This is trained using optimization algorithms using [backpropagation](https://en.wikipedia.org/wiki/Backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House price regression using neural networks\n",
    "\n",
    "For a single hidden layer neural network, then this collapses to logistic regression. We will here implement the network outlined above with a single output neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read and normalize features\n",
    "def featureNormalize(X):\n",
    "    X_norm = X\n",
    "    mu    = np.zeros((1, X.shape[1]))\n",
    "    sigma = np.zeros((1, X.shape[1]))\n",
    "    for i in range(X.shape[1]):\n",
    "        mu[:,i] = np.mean(X[:,i])\n",
    "        sigma[:,i] = np.std(X[:,i])\n",
    "        X_norm[:,i] = (X[:,i] - float(mu[:,i]))/float(sigma[:,i])\n",
    "    return X_norm, mu, sigma\n",
    "\n",
    "data = np.loadtxt('./data/housing_data.csv', delimiter=\",\")\n",
    "X = data[:,:2]\n",
    "y = data[:,2]\n",
    "m = len(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will in the following use the square sum loss function\n",
    "$$\n",
    "J(\\Theta) = \\frac{1}{2m}\\sum(y-y_p)^2\n",
    "$$\n",
    "with the following gradient\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\Theta_ij} = \\frac{1}{m}\\sum(y-y_p)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(W,X,y):\n",
    "    (n,m) = X.shape # n features, m training examples\n",
    "    \n",
    "    Theta1 = np.reshape(W[  : 9], (3,3))\n",
    "    Theta2 = np.reshape(W[ 9:25], (4,4))\n",
    "    Theta3 = np.reshape(W[25:  ], (5,1))\n",
    "    z1 = Theta1 * np.vstack(np.ones((1,m)),  X)\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = Theta2 * np.vstack(np.ones((1,m)), a1)\n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = Theta3 * np.vstack(np.ones((1,m)), a2)\n",
    "    yp = sigmoid(z3) # predicted values for one feed-forward iteration\n",
    "    \n",
    "    loss = np.sum((yp-y)**2) / 2 / m\n",
    "    \n",
    "    # compute the jacobian by partial differentiation\n",
    "    return (loss, jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Neural Network...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'minimize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a30c37ecb435>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmaxiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlambda_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'disp'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'maxiter'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mall_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'minimize' is not defined"
     ]
    }
   ],
   "source": [
    "print('Training Neural Network...')\n",
    "maxiter = 1000\n",
    "lambda_reg = 0.1\n",
    "results = minimize(cost, x0=nn_params, args=(X,y), options={'disp': True, 'maxiter':maxiter}, method=\"L-BFGS-B\", jac=True)\n",
    "\n",
    "all_weights = results[\"x\"]\n",
    "\n",
    "Theta1 = np.reshape(all_weights[  : 9], (3,3), order='F')\n",
    "Theta2 = np.reshape(all_weights[ 9:25], (4,4), order='F')\n",
    "Theta3 = np.reshape(all_weights[25:  ], (5,1), order='F')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displayData(X, example_width=None):\n",
    "    m,n = X.shape\n",
    "    plt.figure(figsize=(16,16))\n",
    "    if X.ndim == 1:\n",
    "        X = np.reshape(X, (-1,m))\n",
    "    if not example_width or not 'example_width' in locals():\n",
    "        example_width = int(round(math.sqrt(X.shape[1])))\n",
    "    plt.set_cmap(\"gray\")\n",
    "    example_height = n / example_width\n",
    "    display_rows = int(math.floor(math.sqrt(m)))\n",
    "    display_cols = int(math.ceil(m / display_rows))\n",
    "    pad = 1\n",
    "    display_array = -np.ones((pad + display_rows * int(example_height + pad),  pad + display_cols * int(example_width + pad)))\n",
    "    curr_ex = 1\n",
    "    for j in range(1,display_rows+1):\n",
    "        for i in range (1,display_cols+1):\n",
    "            if curr_ex > m:\n",
    "                break\n",
    "            max_val = max(abs(X[curr_ex-1, :]))\n",
    "            rows = pad + (j - 1) * (int(example_height) + pad) + np.array(range(int(example_height)))\n",
    "            cols = pad + (i - 1) * (int(example_width)  + pad) + np.array(range(int(example_width)))\n",
    "            display_array[rows[0]:rows[-1]+1 , cols[0]:cols[-1]+1] = np.reshape(X[curr_ex-1, :], (int(example_height), int(example_width)), order=\"F\") / max_val\n",
    "            curr_ex += 1\n",
    "            if curr_ex > m:\n",
    "                break\n",
    "    h = plt.imshow(display_array.T, vmin=-1, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.show(block=False)\n",
    "    return h, display_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(Theta1, Theta2, X):\n",
    "    if X.ndim == 1:\n",
    "        X = np.reshape(X, (-1,X.shape[0]))\n",
    "    m = X.shape[0]\n",
    "    p = np.zeros((m,1))\n",
    "    X = np.column_stack((np.ones((m,1)), X))\n",
    "    a2 = sigmoid( np.dot(X,Theta1.T) )\n",
    "    a2 = np.column_stack((np.ones((a2.shape[0],1)), a2))\n",
    "    a3 = sigmoid( np.dot(a2,Theta2.T) )\n",
    "    p = np.argmax(a3, axis=1)\n",
    "    return p + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture of Deep Neural Network, Cost Function and Regularization\n",
    "<img src='./images/dnncost.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nnCostFunction(nn_params, input_layer_size, hidden_layer_size, \\\n",
    "\tnum_labels, X, y, lambda_reg):\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], \\\n",
    "                     (hidden_layer_size, input_layer_size + 1), order='F')\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):], \\\n",
    "                     (num_labels, hidden_layer_size + 1), order='F')\n",
    "    m = len(X)\n",
    "    J = 0;\n",
    "    Theta1_grad = np.zeros( Theta1.shape )\n",
    "    Theta2_grad = np.zeros( Theta2.shape )\n",
    "    X = np.column_stack((np.ones((m,1)), X)) # = a1\n",
    "    a2 = sigmoid( np.dot(X,Theta1.T) )\n",
    "    a2 = np.column_stack((np.ones((a2.shape[0],1)), a2))\n",
    "    a3 = sigmoid( np.dot(a2,Theta2.T) )\n",
    "\n",
    "    labels = y\n",
    "    #One hot encoding\n",
    "    y = np.zeros((m,num_labels))\n",
    "    for i in range(m):\n",
    "    \ty[i, labels[i]-1] = 1\n",
    "\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "    \tcost += np.sum( y[i] * np.log( a3[i] ) + (1 - y[i]) * np.log( 1 - a3[i] ) )\n",
    "    J = -(1.0/m)*cost\n",
    "    sumOfTheta1 = np.sum(np.sum(Theta1[:,1:]**2))\n",
    "    sumOfTheta2 = np.sum(np.sum(Theta2[:,1:]**2))\n",
    "    J = J + ( (lambda_reg/(2.0*m))*(sumOfTheta1+sumOfTheta2) )\n",
    "    bigDelta1 = 0\n",
    "    bigDelta2 = 0\n",
    "    for t in range(m):\n",
    "        x = X[t]\n",
    "        a2 = sigmoid( np.dot(x,Theta1.T))\n",
    "        a2 = np.concatenate((np.array([1]), a2))\n",
    "        a3 = sigmoid( np.dot(a2,Theta2.T) )\n",
    "        delta3 = np.zeros((num_labels))\n",
    "        for k in range(num_labels):\n",
    "            y_k = y[t, k]\n",
    "            delta3[k] = a3[k] - y_k\n",
    "        delta2 = (np.dot(Theta2[:,1:].T, delta3).T) * sigmoidGradient( np.dot(x, Theta1.T) )\n",
    "        bigDelta1 += np.outer(delta2, x)\n",
    "        bigDelta2 += np.outer(delta3, a2)\n",
    "    Theta1_grad = bigDelta1 / m\n",
    "    Theta2_grad = bigDelta2 / m\n",
    "    Theta1_grad_unregularized = np.copy(Theta1_grad)\n",
    "    Theta2_grad_unregularized = np.copy(Theta2_grad)\n",
    "    Theta1_grad += (float(lambda_reg)/m)*Theta1\n",
    "    Theta2_grad += (float(lambda_reg)/m)*Theta2\n",
    "    Theta1_grad[:,0] = Theta1_grad_unregularized[:,0]\n",
    "    Theta2_grad[:,0] = Theta2_grad_unregularized[:,0]\n",
    "    grad = np.concatenate((Theta1_grad.reshape(Theta1_grad.size, order='F'), Theta2_grad.reshape(Theta2_grad.size, order='F')))\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randInitializeWeights(L_in, L_out):\n",
    "    W = np.zeros((L_out, 1 + L_in))\n",
    "    epsilon_init = 0.12\n",
    "    W = np.random.rand(L_out, 1 + L_in)*(2*epsilon_init) - epsilon_init\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3839c3c0eadb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c20ff6a4c57d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# building the input vector from the 28x28 pixels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_layer_size\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhidden_layer_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m   \u001b[1;31m# 25 hidden units\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "_,input_layer_size  = X_train.shape  \n",
    "hidden_layer_size = 25   # 25 hidden units\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resulting 2 Layer Neural Network\n",
    "<img src='./images/ann.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2f0958b8c3c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrand_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X=X_train\n",
    "y=y_train\n",
    "m,n=X.shape\n",
    "y=y.flatten()\n",
    "rand_indices = np.random.permutation(m)\n",
    "random_images = X[rand_indices[:100],:]\n",
    "displayData(random_images);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_layer_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-fd042a9f5709>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTheta1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandInitializeWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mTheta2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandInitializeWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnn_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTheta1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTheta1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTheta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTheta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_layer_size' is not defined"
     ]
    }
   ],
   "source": [
    "Theta1=randInitializeWeights(input_layer_size,hidden_layer_size)\n",
    "Theta2=randInitializeWeights(hidden_layer_size, num_labels)\n",
    "nn_params = np.concatenate((Theta1.reshape(Theta1.size, order='F'), Theta2.reshape(Theta2.size, order='F')))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Neural Network...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_layer_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d37e83a5e3a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmaxiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlambda_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmyargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_layer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnCostFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'disp'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'maxiter'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_layer_size' is not defined"
     ]
    }
   ],
   "source": [
    "print('Training Neural Network...')\n",
    "maxiter = 1000\n",
    "lambda_reg = 0.1\n",
    "myargs = (input_layer_size, hidden_layer_size, num_labels, X, y, lambda_reg)\n",
    "results = minimize(nnCostFunction, x0=nn_params, args=myargs, options={'disp': True, 'maxiter':maxiter}, method=\"L-BFGS-B\", jac=True)\n",
    "\n",
    "nn_params = results[\"x\"]\n",
    "\n",
    "Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], \\\n",
    "                 (hidden_layer_size, input_layer_size + 1), order='F')\n",
    "\n",
    "Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):], \\\n",
    "                 (num_labels, hidden_layer_size + 1), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizing Neural Network layer 1 \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Theta1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bc7182f8717d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nVisualizing Neural Network layer 1 \\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdisplayData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTheta1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Theta1' is not defined"
     ]
    }
   ],
   "source": [
    "print('\\nVisualizing Neural Network layer 1 \\n')\n",
    "displayData(Theta1[:, 1:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizing Neural Network layer 1 \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Theta2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-27eabb0420f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nVisualizing Neural Network layer 1 \\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdisplayData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTheta2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Theta2' is not defined"
     ]
    }
   ],
   "source": [
    "print('\\nVisualizing Neural Network layer 1 \\n')\n",
    "displayData(Theta2[:, 1:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Theta1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-518a36064e7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTheta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTheta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Theta1' is not defined"
     ]
    }
   ],
   "source": [
    "pred = predict(Theta1, Theta2, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6c7dda918960>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#         print(fmt.format(y_elem%10, pred_elem%10))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training Set Accuracy: {:f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#for i in range(m):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "# uncomment code below to see the predictions that don't match\n",
    "# fmt = '{}   {}'\n",
    "# print(fmt.format('y', 'pred'))\n",
    "# for y_elem, pred_elem in zip(y, pred):\n",
    "#     if y_elem != pred_elem:\n",
    "#         print(fmt.format(y_elem%10, pred_elem%10))\n",
    "\n",
    "print('Training Set Accuracy: {:f}'.format( ( np.mean(pred == y)*100 ) ) )\n",
    "\n",
    "#for i in range(m):\n",
    "#    print('Displaying Example Image')\n",
    "#    displayData(X[rp[i], :].reshape(1,-1))\n",
    "#    pred = predict(Theta1, Theta2, X[rp[i], :])\n",
    "#    print('Neural Network Prediction: {:d} (digit {:d})'.format(pred[0], (pred%10)[0]))\n",
    "#    input('Program paused. Press enter to continue.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve using Keras with Tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from decimal import Decimal\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "_,input_layer_size  = X_train.shape  \n",
    "X=X_train\n",
    "y=y_train\n",
    "m,n=X.shape\n",
    "y=y.flatten()\n",
    "rand_indices = np.random.permutation(m)\n",
    "random_images = X[rand_indices[:100],:]\n",
    "displayData(random_images);\n",
    "num_labels=np.unique(y).shape [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "y = np_utils.to_categorical(y)\n",
    "print(\"Shape of y \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ANN_classifier = Sequential()\n",
    "ANN_classifier.add(Dense(units = 25, kernel_initializer = 'normal', activation = 'relu', input_dim = input_layer_size))\n",
    "ANN_classifier.add(Dense(units = num_labels, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "ANN_classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history=ANN_classifier.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create randomized index\n",
    "rp = np.random.permutation(len(X_test))\n",
    "#Try out on the data\n",
    "for i in range(3):\n",
    "    print('Displaying Example Image')\n",
    "    displayData(X_test[rp[i], :].reshape(1,-1))\n",
    "    pred = ANN_classifier.predict(X_test[rp[i],:].reshape(1,-1))\n",
    "    print('Neural Network Prediction: ',np.argmax(pred))\n",
    "    input('Program paused. Press enter to continue.\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
