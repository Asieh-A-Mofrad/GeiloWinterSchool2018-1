{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import expit\n",
    "from decimal import Decimal\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks\n",
    "\n",
    "Here we will take a closer look at Neural Netorks, also known as Artificial Neural Networks (ANN) to destinuish them from their biological counterparts and Convolutional Neural Networks (CNN); which will be covered in the next session.\n",
    "\n",
    "ANNs simulate the brain architecture in that neurons take gets input from synapses and give output to other neurons, thereby forming a directed graph.  \n",
    "\n",
    "![General neural net graph](./images/general-ann.png)\n",
    "\n",
    "The topology of this graph can be quite diverse, however we will start with a simple example. We will tag some nodes as special input nodes and some as special output nodes. This is were we will attach the input-output training data to later. The rest of the nodes are simply called \"hidden nodes\"\n",
    "\n",
    "![Simple ANN](./images/Artificial_neural_network.svg)\n",
    "\n",
    "A single neuron takes multiple inputs $x_i$ and give a single output (possible to more than one reciever). The inputs are weighted by some $\\theta_i$ to compute an *activation*\n",
    "\n",
    "$z = \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation(x, theta):\n",
    "    answer = 0\n",
    "    for i in range(len(x)):\n",
    "        answer += x[i]*theta[i]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However the activation is typically passed through an activation function. This introduces non-linearity into the formulation which greatly helps in generalizing to complex problems. Different activation functions are available, but the two must videly used are the\n",
    "\n",
    "## sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRLKQyl1EJAup3EVEstD/B7tSUHH+/ynPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1438781fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))\n",
    "\n",
    "z = np.linspace(-8,8)\n",
    "plt.plot(z, sigmoid(z))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rectified linear unit (relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f140cc78a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(z,0)\n",
    "\n",
    "z = np.linspace(-8,8)\n",
    "plt.plot(z, relu(z))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a single neuron with input weights $\\theta_i$ can then be programmed as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron(x,theta):\n",
    "    return sigmoid(activation(x,theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if one choses the sigmoid activation function. Theentire network described above can be written as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define some input vector\n",
    "x = [1,3,13]\n",
    "\n",
    "# compute output for hidden units\n",
    "a1 = neuron(x, [1,1,1]) # output from hidden neuron 1 using weights [1,1,1]\n",
    "a2 = neuron(x, [1,2,1]) # output from hidden neuron 2 using weights [1,2,1]\n",
    "a3 = neuron(x, [3,2,1]) # output from hidden neuron 2 using weights [3,2,1]\n",
    "a4 = neuron(x, [0,0,1]) # output from hidden neuron 2 using weights [0,0,1]\n",
    "a  = [a1,a2,a3,a4]      # wrap all hidden values into a vector\n",
    "\n",
    "# compute output nodes\n",
    "y1 = neuron(a, [0,0,1,3]) # output neuron 1 using weights [0,0,1,3]\n",
    "y2 = neuron(a, [3,9,1,0]) # output neuron 2 using weights [3,9,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that every neuron $i$ has a different weight $\\theta_j$ and we often denote $\\Theta_{ij}$\n",
    "\n",
    "$a = \\sigma(\\Theta x)$\n",
    "\n",
    "Likewise, the output nodes will also have different weights and we write\n",
    "\n",
    "$y = \\sigma(\\Theta^{(2)} a)$\n",
    "\n",
    "where $\\sigma(\\cdot)$ is the activation function (here: sigmoid function). $\\Theta^{(2)} =\\left[\\begin{array}{cccc} 0 & 0 & 1 & 3 \\\\ 3 & 9 & 1 & 0 \\end{array}\\right]$ in this particular case. This vectorization allow us to create fast implementations of neural networks. $x$ and $y$ are as usual treated as the input and output respectively, while intermediate results are denoted $p$. \n",
    "\n",
    "Due to the optimzation possibilities, these *feed forward* networks have become very popular. We can extend this be adding more layers to it. By adding another layer we can start with a vector $x$, then compute a vector $p_1$ using a matrix of weights $\\Theta^{(1)}$. Subsequently we compute a vector $p_2$ using a matrix of weights $\\Theta^{(2)}$ followed by an output using $\\Theta^{(3)}$, giving the following network\n",
    "\n",
    "![Neural network with 2 hidden layers](./images/Artificial_neural_network_2layers.svg)\n",
    "\n",
    "We can control the architecture of the network and the activation functions used, but will not manually specify the weights $\\Theta$. This is trained using optimization algorithms using [backpropagation](https://en.wikipedia.org/wiki/Backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House price regression using neural networks\n",
    "\n",
    "For a single hidden layer neural network, then this collapses to logistic regression. We will here implement the network outlined above with a single output neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read and normalize features\n",
    "def featureNormalize(X):\n",
    "    X_norm = X\n",
    "    mu    = np.zeros((1, X.shape[1]))\n",
    "    sigma = np.zeros((1, X.shape[1]))\n",
    "    for i in range(X.shape[1]):\n",
    "        mu[:,i] = np.mean(X[:,i])\n",
    "        sigma[:,i] = np.std(X[:,i])\n",
    "        X_norm[:,i] = (X[:,i] - float(mu[:,i]))/float(sigma[:,i])\n",
    "    return X_norm, mu, sigma\n",
    "\n",
    "data = np.loadtxt('./data/housing_data.csv', delimiter=\",\")\n",
    "X = data[:,:2]\n",
    "y = data[:,2]\n",
    "m = len(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will in the following use the square sum loss function\n",
    "$$\n",
    "J(\\Theta) = \\frac{1}{2m}\\sum(y-y_p)^2\n",
    "$$\n",
    "with the following gradient\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\Theta_ij} = \\frac{1}{m}\\sum(y-y_p)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(W,X,y):\n",
    "    (n,m) = X.shape # n features, m training examples\n",
    "    \n",
    "    Theta1 = np.reshape(W[  : 9], (3,3))\n",
    "    Theta2 = np.reshape(W[ 9:25], (4,4))\n",
    "    Theta3 = np.reshape(W[25:  ], (5,1))\n",
    "    z1 = Theta1 * np.vstack(np.ones((1,m)),  X)\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = Theta2 * np.vstack(np.ones((1,m)), a1)\n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = Theta3 * np.vstack(np.ones((1,m)), a2)\n",
    "    yp = sigmoid(z3) # predicted values for one feed-forward iteration\n",
    "    \n",
    "    loss = np.sum((yp-y)**2) / 2 / m\n",
    "    \n",
    "    # compute the jacobian by partial differentiation\n",
    "    return (loss, jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training Neural Network...')\n",
    "maxiter = 1000\n",
    "lambda_reg = 0.1\n",
    "results = minimize(cost, x0=nn_params, args=(X,y), options={'disp': True, 'maxiter':maxiter}, method=\"L-BFGS-B\", jac=True)\n",
    "\n",
    "all_weights = results[\"x\"]\n",
    "\n",
    "Theta1 = np.reshape(all_weights[  : 9], (3,3), order='F')\n",
    "Theta2 = np.reshape(all_weights[ 9:25], (4,4), order='F')\n",
    "Theta3 = np.reshape(all_weights[25:  ], (5,1), order='F')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displayData(X, example_width=None):\n",
    "    m,n = X.shape\n",
    "    plt.figure(figsize=(16,16))\n",
    "    if X.ndim == 1:\n",
    "        X = np.reshape(X, (-1,m))\n",
    "    if not example_width or not 'example_width' in locals():\n",
    "        example_width = int(round(math.sqrt(X.shape[1])))\n",
    "    plt.set_cmap(\"gray\")\n",
    "    example_height = n / example_width\n",
    "    display_rows = int(math.floor(math.sqrt(m)))\n",
    "    display_cols = int(math.ceil(m / display_rows))\n",
    "    pad = 1\n",
    "    display_array = -np.ones((pad + display_rows * int(example_height + pad),  pad + display_cols * int(example_width + pad)))\n",
    "    curr_ex = 1\n",
    "    for j in range(1,display_rows+1):\n",
    "        for i in range (1,display_cols+1):\n",
    "            if curr_ex > m:\n",
    "                break\n",
    "            max_val = max(abs(X[curr_ex-1, :]))\n",
    "            rows = pad + (j - 1) * (int(example_height) + pad) + np.array(range(int(example_height)))\n",
    "            cols = pad + (i - 1) * (int(example_width)  + pad) + np.array(range(int(example_width)))\n",
    "            display_array[rows[0]:rows[-1]+1 , cols[0]:cols[-1]+1] = np.reshape(X[curr_ex-1, :], (int(example_height), int(example_width)), order=\"F\") / max_val\n",
    "            curr_ex += 1\n",
    "            if curr_ex > m:\n",
    "                break\n",
    "    h = plt.imshow(display_array.T, vmin=-1, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.show(block=False)\n",
    "    return h, display_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(Theta1, Theta2, X):\n",
    "    if X.ndim == 1:\n",
    "        X = np.reshape(X, (-1,X.shape[0]))\n",
    "    m = X.shape[0]\n",
    "    p = np.zeros((m,1))\n",
    "    X = np.column_stack((np.ones((m,1)), X))\n",
    "    a2 = sigmoid( np.dot(X,Theta1.T) )\n",
    "    a2 = np.column_stack((np.ones((a2.shape[0],1)), a2))\n",
    "    a3 = sigmoid( np.dot(a2,Theta2.T) )\n",
    "    p = np.argmax(a3, axis=1)\n",
    "    return p + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed forward network\n",
    "\n",
    "<img src='./images/ann.jpg'>\n",
    "\n",
    "* Add a column of 1 to the $X$  matrix to account for the bias term and then $A=\\sigma(X\\Theta^{(1)})$\n",
    "* Add a column of 1 to the $A$  matrix to account for the bias term and then $H_{\\Theta}=\\sigma(A\\Theta^{(2)})$\n",
    "\n",
    "<b>Cost Function</b>\n",
    "\n",
    "$J(\\Theta)=-\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{i=1}^{K}[y_{k}^{(i)} log((H_{\\Theta}(x^{(i)}))_{k}) + (1-y_{k}^{(i)}) log(1-(H_{\\Theta}(x^{(i)}))_{k})+\\frac{\\lambda}{2m}\\sum_{l=1}^{2}\\sum_{i=1}^{sl} (\\Theta_{j,i}^{(l)})^{2}]$\n",
    "\n",
    "<b>Back Propagation</b>\n",
    "\n",
    "The cost function $J(\\Theta)$ is minimized using the Back Propagation algorithm which gives the optimal values for $\\Theta^{(1)}$ and $\\Theta^{(2)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nnCostFunction(nn_params, input_layer_size, hidden_layer_size, \\\n",
    "\tnum_labels, X, y, lambda_reg):\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], \\\n",
    "                     (hidden_layer_size, input_layer_size + 1), order='F')\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):], \\\n",
    "                     (num_labels, hidden_layer_size + 1), order='F')\n",
    "    m = len(X)\n",
    "    J = 0;\n",
    "    Theta1_grad = np.zeros( Theta1.shape )\n",
    "    Theta2_grad = np.zeros( Theta2.shape )\n",
    "    X = np.column_stack((np.ones((m,1)), X)) # = a1\n",
    "    a2 = sigmoid( np.dot(X,Theta1.T) )\n",
    "    a2 = np.column_stack((np.ones((a2.shape[0],1)), a2))\n",
    "    a3 = sigmoid( np.dot(a2,Theta2.T) )\n",
    "\n",
    "    labels = y\n",
    "    #One hot encoding\n",
    "    y = np.zeros((m,num_labels))\n",
    "    for i in range(m):\n",
    "    \ty[i, labels[i]-1] = 1\n",
    "\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "    \tcost += np.sum( y[i] * np.log( a3[i] ) + (1 - y[i]) * np.log( 1 - a3[i] ) )\n",
    "    J = -(1.0/m)*cost\n",
    "    sumOfTheta1 = np.sum(np.sum(Theta1[:,1:]**2))\n",
    "    sumOfTheta2 = np.sum(np.sum(Theta2[:,1:]**2))\n",
    "    J = J + ( (lambda_reg/(2.0*m))*(sumOfTheta1+sumOfTheta2) )\n",
    "    bigDelta1 = 0\n",
    "    bigDelta2 = 0\n",
    "    for t in range(m):\n",
    "        x = X[t]\n",
    "        a2 = sigmoid( np.dot(x,Theta1.T))\n",
    "        a2 = np.concatenate((np.array([1]), a2))\n",
    "        a3 = sigmoid( np.dot(a2,Theta2.T) )\n",
    "        delta3 = np.zeros((num_labels))\n",
    "        for k in range(num_labels):\n",
    "            y_k = y[t, k]\n",
    "            delta3[k] = a3[k] - y_k\n",
    "        delta2 = (np.dot(Theta2[:,1:].T, delta3).T) * sigmoidGradient( np.dot(x, Theta1.T) )\n",
    "        bigDelta1 += np.outer(delta2, x)\n",
    "        bigDelta2 += np.outer(delta3, a2)\n",
    "    Theta1_grad = bigDelta1 / m\n",
    "    Theta2_grad = bigDelta2 / m\n",
    "    Theta1_grad_unregularized = np.copy(Theta1_grad)\n",
    "    Theta2_grad_unregularized = np.copy(Theta2_grad)\n",
    "    Theta1_grad += (float(lambda_reg)/m)*Theta1\n",
    "    Theta2_grad += (float(lambda_reg)/m)*Theta2\n",
    "    Theta1_grad[:,0] = Theta1_grad_unregularized[:,0]\n",
    "    Theta2_grad[:,0] = Theta2_grad_unregularized[:,0]\n",
    "    grad = np.concatenate((Theta1_grad.reshape(Theta1_grad.size, order='F'), Theta2_grad.reshape(Theta2_grad.size, order='F')))\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randInitializeWeights(L_in, L_out):\n",
    "    W = np.zeros((L_out, 1 + L_in))\n",
    "    epsilon_init = 0.12\n",
    "    W = np.random.rand(L_out, 1 + L_in)*(2*epsilon_init) - epsilon_init\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "_,input_layer_size  = X_train.shape  \n",
    "hidden_layer_size = 25   # 25 hidden units\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X_train\n",
    "y=y_train\n",
    "m,n=X.shape\n",
    "y=y.flatten()\n",
    "rand_indices = np.random.permutation(m)\n",
    "random_images = X[rand_indices[:100],:]\n",
    "displayData(random_images);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Theta1=randInitializeWeights(input_layer_size,hidden_layer_size)\n",
    "Theta2=randInitializeWeights(hidden_layer_size, num_labels)\n",
    "nn_params = np.concatenate((Theta1.reshape(Theta1.size, order='F'), Theta2.reshape(Theta2.size, order='F')))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training Neural Network...')\n",
    "maxiter = 1000\n",
    "lambda_reg = 0.1\n",
    "myargs = (input_layer_size, hidden_layer_size, num_labels, X, y, lambda_reg)\n",
    "results = minimize(nnCostFunction, x0=nn_params, args=myargs, options={'disp': True, 'maxiter':maxiter}, method=\"L-BFGS-B\", jac=True)\n",
    "\n",
    "nn_params = results[\"x\"]\n",
    "\n",
    "Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], \\\n",
    "                 (hidden_layer_size, input_layer_size + 1), order='F')\n",
    "\n",
    "Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):], \\\n",
    "                 (num_labels, hidden_layer_size + 1), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\\nVisualizing Neural Network layer 1 \\n')\n",
    "displayData(Theta1[:, 1:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\\nVisualizing Neural Network layer 1 \\n')\n",
    "displayData(Theta2[:, 1:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = predict(Theta1, Theta2, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment code below to see the predictions that don't match\n",
    "# fmt = '{}   {}'\n",
    "# print(fmt.format('y', 'pred'))\n",
    "# for y_elem, pred_elem in zip(y, pred):\n",
    "#     if y_elem != pred_elem:\n",
    "#         print(fmt.format(y_elem%10, pred_elem%10))\n",
    "\n",
    "print('Training Set Accuracy: {:f}'.format( ( np.mean(pred == y)*100 ) ) )\n",
    "\n",
    "#for i in range(m):\n",
    "#    print('Displaying Example Image')\n",
    "#    displayData(X[rp[i], :].reshape(1,-1))\n",
    "#    pred = predict(Theta1, Theta2, X[rp[i], :])\n",
    "#    print('Neural Network Prediction: {:d} (digit {:d})'.format(pred[0], (pred%10)[0]))\n",
    "#    input('Program paused. Press enter to continue.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve using Keras with Tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from decimal import Decimal\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "_,input_layer_size  = X_train.shape  \n",
    "X=X_train\n",
    "y=y_train\n",
    "m,n=X.shape\n",
    "y=y.flatten()\n",
    "rand_indices = np.random.permutation(m)\n",
    "random_images = X[rand_indices[:100],:]\n",
    "displayData(random_images);\n",
    "num_labels=np.unique(y).shape [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "y = np_utils.to_categorical(y)\n",
    "print(\"Shape of y \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ANN_classifier = Sequential()\n",
    "ANN_classifier.add(Dense(units = 25, kernel_initializer = 'normal', activation = 'relu', input_dim = input_layer_size))\n",
    "ANN_classifier.add(Dense(units = num_labels, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "ANN_classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history=ANN_classifier.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create randomized index\n",
    "rp = np.random.permutation(len(X_test))\n",
    "#Try out on the data\n",
    "for i in range(3):\n",
    "    print('Displaying Example Image')\n",
    "    displayData(X_test[rp[i], :].reshape(1,-1))\n",
    "    pred = ANN_classifier.predict(X_test[rp[i],:].reshape(1,-1))\n",
    "    print('Neural Network Prediction: ',np.argmax(pred))\n",
    "    input('Program paused. Press enter to continue.\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
